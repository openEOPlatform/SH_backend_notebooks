{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://avatars.githubusercontent.com/u/74911464?s=200&v=4\"\n",
    "     alt=\"OpenEO Platform logo\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "# OpenEO Platform - SH openEO backend data fusion use case\n",
    "### Calculate mean NDVI of data fusion of 2 collections over time (as synchronous and batch job) and export the result (locally, via signed URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Open the connect to openEO Platform (development backend) and authenticate**  \n",
    "- establish connection to the openEO Platform back-end\n",
    "- connection object is your central gateway to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo.rest.auth.config import RefreshTokenStore\n",
    "RefreshTokenStore().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to openEO Platform back-end (https://openeo.cloud) which has the SH production backend implemented (properties={\"provider:backend\":lambda v: v ==\"sentinelhub\"} needs to be added to the load_collection process)\n",
    "# Currently only available on testing (https://openeo-dev.sinergise.com/testing)\n",
    "connection = openeo.connect(\"https://openeo-dev.sinergise.com/testing\")\n",
    "\n",
    "# Authenticate via EGI\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Define spatial and temporal extent, bands and specify backend to be used for 2 collections**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data cube from Sentinel2_L2A collection for a 3-weeks cloud free priod in July 2021 north of Ljubljana\n",
    "# (5 aquisitions)\n",
    "cube_l2a = connection.load_collection(\n",
    "    \"SENTINEL2_L2A_SENTINELHUB\",\n",
    "    spatial_extent={\"west\": 14.583040689005495, \"south\": 46.10348118219517, \"east\": 14.599965321685639, \n",
    "                    \"north\": 46.11226598409823},\n",
    "    temporal_extent=[\"2021-07-09\", \"2022-07-30\"],\n",
    "    bands=[\"B01\", \"B04\"]\n",
    ")\n",
    "\n",
    "# Load data cube from Sentinel2_L1C collection for a 3-weeks cloud free priod in July 2021 north of Ljubljana\n",
    "# (5 aquisitions)\n",
    "cube_l1c = connection.load_collection(\n",
    "    \"SENTINEL2_L1C_SENTINELHUB\",\n",
    "    spatial_extent={\"west\": 14.583040689005495, \"south\": 46.10348118219517, \"east\": 14.599965321685639, \n",
    "                    \"north\": 46.11226598409823},\n",
    "    temporal_extent=[\"2021-07-09\", \"2022-07-30\"],\n",
    "    bands=[\"B02\", \"B08\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Merge the datacubes together into a single datacube**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_cube = cube_l2a.merge_cubes(cube_l1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Calculate the mean over the temporal extent and afterward calculate the NDVI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of B04 and B08\n",
    "merged_cube_mean = merged_cube.reduce_dimension(dimension=\"t\", reducer=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI\n",
    "merged_cube_mean_ndvi_all_bands = merged_cube_mean.ndvi(nir = \"B08\", red = \"B04\", target_band = \"NDVI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter bands\n",
    "merged_cube_mean_ndvi = merged_cube_mean_ndvi_all_bands.filter_bands([\"NDVI\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronous processing\n",
    "**5. Download data synchronously**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on the backend load this synchronous call sometimes times out\n",
    "# as the result is part of the repository you can continue with the next cell \n",
    "# and visualize the result and run the job as batch job\n",
    "merged_cube_mean_ndvi.download(\"merged_cube_mean_ndvi.tiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Plot NDVI data on map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open into an xarray.DataArray\n",
    "geotiff_da = rioxarray.open_rasterio(\"./merged_cube_mean_ndvi.tiff\")\n",
    "\n",
    "# Covert our xarray.DataArray into a xarray.Dataset\n",
    "geotiff_ds = geotiff_da.to_dataset('band').rename({1: 'NDVI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean NDVI data on map\n",
    "geotiff_ds.NDVI.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch processing\n",
    "**5. Save results as Geotiff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "merged_cube_mean_ndvi_tiff = merged_cube_mean_ndvi.save_result(format=\"GTiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Create a batch job and start it.**\n",
    "\n",
    "More info about batch jobs can be found here:\n",
    "\n",
    "- https://openeo.org/documentation/1.0/glossary.html#data-processing-modes\n",
    "\n",
    "- https://open-eo.github.io/openeo-python-client/batch_jobs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the job \n",
    "job = merged_cube_mean_ndvi_tiff.create_job(title = 'Data_Fusion_Mean_NDVI_Ljubljana_demo')\n",
    "\n",
    "# save job id and print it\n",
    "job_id = job.job_id\n",
    "print(\"Batch job created with id: \",job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the job\n",
    "job.start_job() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output batch job status \n",
    "print(\"Batch job with id: \",job_id, ' is ',job.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. When batch job status is `finished`, get job metadata via signed URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get job metadata to get signed URL from Assets\n",
    "job = connection.job(job_id)\n",
    "job.get_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
